{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dicitonary with pairs (metric_name, list_of_results)\n",
    "# model must have .fit() and .predict() methods\n",
    "def k_fold_cv(model, df:pd.DataFrame, k=10, metric_funcs:list=[f1_score, accuracy_score, roc_auc_score]):\n",
    "\n",
    "    def valid_proportions(folds: list[pd.DataFrame]):\n",
    "        fix_prop = df['malignancy'].value_counts(normalize=True, sort=False).to_dict()\n",
    "        for fold in folds:\n",
    "            fold_prop = fold['malignancy'].value_counts(normalize=True, sort=False).to_dict()\n",
    "            error = 0\n",
    "            for k in fold_prop.keys():\n",
    "                error += (fix_prop[k] - fold_prop[k])**2\n",
    "            if error > 0.1:\n",
    "                return False\n",
    "        return True            \n",
    "\n",
    "    folds = []\n",
    "    pid_list = df['patient_id'].unique()\n",
    "    while True:\n",
    "        shuffled_pid_list = pd.Series(pid_list).sample(frac=1).to_list()\n",
    "        for pid in range(0, len(pid_list), len(pid_list)//k):\n",
    "            pid_fold = shuffled_pid_list[pid : pid+len(pid_list)//k]\n",
    "            fold_df = df[df['patient_id'].isin(pid_fold)]\n",
    "            folds.append(fold_df)\n",
    "        \n",
    "        if valid_proportions(folds): break\n",
    "        else: folds = []\n",
    "    if len(folds) == k+1:\n",
    "        last_fold = folds[-1]\n",
    "        for index, pid in enumerate(last_fold['patient_id'].unique()):\n",
    "            folds[index].append(last_fold[last_fold['patient_id']==pid])\n",
    "        folds = folds[0:-1]\n",
    "\n",
    "    metrics_results = dict((metric_fn.__name__, []) for metric_fn in metric_funcs)\n",
    "    metrics_results['weights'] = []\n",
    "    for test_fold_index in range(len(folds)):\n",
    "        testing_df = folds[test_fold_index]\n",
    "        training_df = pd.DataFrame(columns=df.columns)\n",
    "        for fold_index, fold_df in enumerate(folds):\n",
    "            if fold_index == test_fold_index:\n",
    "                continue\n",
    "            training_df.append(fold_df)\n",
    "\n",
    "        X_train, y_train = training_df.drop(columns=['malignancy']), training_df['malignancy']\n",
    "        X_test, y_test = testing_df.drop(columns=['malignancy']), testing_df['malignancy']\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        for metric_fn in metric_funcs:\n",
    "            metrics_results[metric_fn.__name__].append(metric_fn(y_test, y_pred))\n",
    "        metrics_results['weights'].append(testing_df.shape[0] / df.shape[0])\n",
    "        \n",
    "    return metrics_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_avg_and_std(values, weights):\n",
    "    average = np.average(values, weights=weights)\n",
    "    variance = np.average((values-average)**2, weights=weights)\n",
    "    return average, math.sqrt(variance)\n",
    "\n",
    "# returns a dataframe with the mean and standard deviation from the results of a K-fold CV\n",
    "def mean_std_results_k_fold_CV(k_fold_metrics_results: dict[str, list]):\n",
    "    results_df = pd.DataFrame(columns=['metric', 'mean', 'std'])\n",
    "    metrics_weights = np.array(k_fold_metrics_results['weights'])\n",
    "    for metric_name, metric_results in k_fold_metrics_results.items():\n",
    "        if metric_name == 'weights':\n",
    "            continue\n",
    "        mean, std = weighted_avg_and_std(np.array(metric_results), weights=metrics_weights)\n",
    "        results_df.append({\n",
    "            'metric': metric_name,\n",
    "            'mean': mean,\n",
    "            'std': std\n",
    "        })\n",
    "    return results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_iacd_project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
