{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylidc as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classified = pd.read_excel(\"tcia-diagnosis-data-2012-04-20.xls\")\n",
    "classified_examples_list = df_classified.iloc[:, 0].to_list()\n",
    "\n",
    "df_annotations = pd.read_csv(\"LabIACD Project 1/LabIACD-Project-1/Data/features.csv\")\n",
    "classified_examples_annotations_df = df_annotations[df_annotations[\"patient_id\"].isin(classified_examples_list)].iloc[:, [0,6]]\n",
    "\n",
    "classified_examples_annotations_dict = {}\n",
    "for patient_id in classified_examples_list:\n",
    "    annotation_ids = classified_examples_annotations_df[classified_examples_annotations_df[\"patient_id\"] == patient_id].iloc[:,1].to_list()\n",
    "    if len(annotation_ids) > 0:\n",
    "        classified_examples_annotations_dict[patient_id] = annotation_ids\n",
    "\n",
    "for p_id, ann_id in classified_examples_annotations_dict.items():\n",
    "    print(f\"{p_id}: {ann_id}\")\n",
    "\n",
    "with open(\"classified_examples_annotations_dict.pkl\", \"wb\") as file:\n",
    "    pickle.dump(classified_examples_annotations_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_frame_size(patients_annotations_dict: dict[str, list[int]]):\n",
    "    height_max = width_max = 0\n",
    "\n",
    "    for index, pid in enumerate(patients_annotations_dict.keys()):\n",
    "        scan = pl.query(pl.Scan).filter(pl.Scan.patient_id == pid).first()\n",
    "        print(f\"At scan {index+1} / {len(patients_annotations_dict)}\")\n",
    "\n",
    "        for a in scan.annotations:\n",
    "            bbox = a.bbox()\n",
    "            height, width, _ = a.scan.to_volume(verbose=False)[bbox].shape\n",
    "            height_max = max(height_max, height)\n",
    "            width_max = max(width_max, width)\n",
    "    \n",
    "    # preventing from height_max and width_max being odd values\n",
    "    if height_max%2 == 1: height_max += 1\n",
    "    if width_max%2 == 1: width_max += 1\n",
    "    return height_max, width_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zoomed_out_bbox(cur_bbox, i_range, j_range):\n",
    "    i_middle = cur_bbox[0].start + (cur_bbox[0].stop - cur_bbox[0].start) // 2\n",
    "    j_middle = cur_bbox[1].start + (cur_bbox[1].stop - cur_bbox[1].start) // 2\n",
    "\n",
    "    i_slice_limits = [i_middle - i_range//2, i_middle + i_range//2]\n",
    "    j_slice_limits = [j_middle - j_range//2, j_middle + j_range//2]\n",
    "\n",
    "    if i_slice_limits[0] < 0:\n",
    "        i_slice_limits[1] += -1*i_slice_limits[0]\n",
    "        i_slice_limits[0] = 0\n",
    "    \n",
    "    if j_slice_limits[0] < 0:\n",
    "        j_slice_limits[1] += -1*j_slice_limits[0]\n",
    "        j_slice_limits[0] = 0\n",
    "\n",
    "    if i_slice_limits[1] >= 512:\n",
    "        i_slice_limits[0] -= i_slice_limits[1]-512\n",
    "        i_slice_limits[1] = 511\n",
    "    \n",
    "    if j_slice_limits[1] >= 512:\n",
    "        j_slice_limits[0] -= j_slice_limits[1]-512\n",
    "        j_slice_limits[1] = 511\n",
    "\n",
    "    i_slice = slice(i_slice_limits[0], i_slice_limits[1], None)\n",
    "    j_slice = slice(j_slice_limits[0], j_slice_limits[1], None)\n",
    "\n",
    "    return (i_slice, j_slice, cur_bbox[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves the masked version of the nodules with thei respecitve annotations\n",
    "# also saves a csv table with columns \"Patiend_ID\" \"Annotation_ID\" and \"Masked_Image_Path\"\n",
    "def get_masked_nodules_pictures(patients_annotations_dict: dict[str, list[int]], frame_height=100, frame_width=100):\n",
    "    df = []\n",
    "    \n",
    "    for index, pid in enumerate(patients_annotations_dict.keys()):\n",
    "\n",
    "        print(f\"Current Patient: {pid} | {index+1}/{len(patients_annotations_dict)}\")\n",
    "        scan = pl.query(pl.Scan).filter(pl.Scan.patient_id == pid).first()\n",
    "        ann_list = patients_annotations_dict[pid]\n",
    "\n",
    "        for ann_i, annotation in enumerate(scan.annotations):\n",
    "            \n",
    "            bbox = get_zoomed_out_bbox(annotation.bbox(), frame_height, frame_width)\n",
    "            bbox_np = np.array([[row.start, row.stop] for row in bbox])\n",
    "            vol = annotation.scan.to_volume(verbose=False)\n",
    "            mask = annotation.boolean_mask(bbox=bbox_np)\n",
    "            z = math.floor(vol[bbox].shape[2] / 2) \n",
    "            mask_map = np.array(mask[:,:,z])\n",
    "            masked_image = np.array(vol[bbox][:,:,z]) \n",
    "            \n",
    "            # modifying the original image such that:\n",
    "            #     if mask_map[i][j] == False --> image[i][j] = black\n",
    "            #     if mask_map[i][j] == True  --> image[i][j] is preserved\n",
    "            for i in range(len(mask_map)-1):\n",
    "                for j in range(len(mask_map[0])-1):\n",
    "                    if mask_map[i][j] == False:\n",
    "                        masked_image[i][j] = -1000 # black color value\n",
    "            \n",
    "            masked_image_path = f\"masked_images/annotation-{ann_list[ann_i]}.png\"\n",
    "            mpimg.imsave(masked_image_path, masked_image, cmap=\"gray\")\n",
    "            df.append({\"patient_id\": pid, \"annotation_id\": ann_list[ann_i], \"masked_imagepPath\": masked_image_path})\n",
    "    \n",
    "    with open(\"masked_images_dict.pkl\", \"wb\") as save_df:\n",
    "        pickle.dump(df, save_df)\n",
    "\n",
    "    print(\"Finished masking!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_examples_annotations_dict = dict()\n",
    "with open(\"classified_examples_annotations_dict.pkl\", \"rb\") as pid_list:\n",
    "    classified_examples_annotations_dict = pickle.load(pid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = get_max_frame_size(classified_examples_annotations_dict)\n",
    "print(f\"The images will have size [{width}]x[{height}] pixels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_masked_nodules_pictures(classified_examples_annotations_dict, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dicts = list()\n",
    "with open(\"masked_images_dict.pkl\", \"rb\") as dicts:\n",
    "    df_dicts = pickle.load(dicts)\n",
    "\n",
    "df = pd.DataFrame(df_dicts, columns=[\"Patient_ID\", \"Annotation_ID\", \"Masked_Image_Path\"])\n",
    "df.to_csv(\"masked_annotation_images.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
