{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "One of the models we chose to implement for the purpose of lung cancer classification was XGBoost, a gradient boosting algorithm.  \n",
    "This is the fastest implementation of gradient boosting and dominates tabular datasets on classification predictive modeling problems.\n",
    "\n",
    "We start by importing relevant libraries and dropping useless columns from our CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier \n",
    "from kfold_and_metrics import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final.csv\")\n",
    "df = df.drop(columns=[\"id\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Hypertuning\n",
    "\n",
    "In order to prevent overfitting, we hypertuned our model on the values of the number of estimators, max depth and max samples per leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_auc = 0\n",
    "best = {}\n",
    "\n",
    "for n_est in range(25, 201, 25):\n",
    "    for m_depth in range(5, 56, 10):\n",
    "        for m_samples_leaf in range(5, 26, 5):\n",
    "            params = {'n_estimators': n_est, 'max_depth': m_depth, 'min_samples_leaf': m_samples_leaf}\n",
    "            print(\"Current parameter combination:\")\n",
    "            for parameter, value in params.items():\n",
    "                print(f\"\\t{parameter}: {value}\")\n",
    "            print()\n",
    "            \n",
    "            model = GradientBoostingClassifier(n_estimators=n_est, max_depth=m_depth, min_samples_leaf=m_samples_leaf)\n",
    "            auc_results = k_fold_cv(model, df, metric_funcs=[roc_auc_score], pca_components=50, k_fold_verbose=True)\n",
    "            auc_average, auc_std = weighted_avg_and_std(np.array(auc_results['roc_auc_score']))\n",
    "            if auc_average > best_auc:\n",
    "                best_auc = auc_average\n",
    "                best = params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running, we got the following values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results of the grid search parameter hypertunning:\")\n",
    "for parameter, value in best.items():\n",
    "    print(f\"\\t{parameter}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
