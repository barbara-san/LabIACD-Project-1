{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "One of the models we chose to implement for the purpose of lung cancer classification was Random Forest, an ensemble learning method that constructs a multitude of decision trees at training time.  \n",
    "This algorithm is suitable for classification prediction problems, handles a lot of features well and lets us easily check the relative importance assigned to each.\n",
    "\n",
    "We start by importing relevant libraries and dropping useless columns from our CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kfold_and_metrics import *\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final.csv\")\n",
    "df = df.drop(columns=[\"id\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Hypertuning\n",
    "\n",
    "In order to prevent overfitting, we hypertuned our model on the values of the number of estimators, max depth and max samples per leaf.  \n",
    "We also tested which of the evaluation criteria suited our data best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_auc = 0\n",
    "best = {}\n",
    "\n",
    "for crit in [\"gini\", \"entropy\", \"log_loss\"]:\n",
    "    for n_est in range(30, 201, 10):\n",
    "        for m_depth in range(10, 31):\n",
    "            for m_samples_leaf in range(5, 21):\n",
    "                params = {'n_estimators': n_est, 'max_depth': m_depth, 'min_samples_leaf': m_samples_leaf, 'criterion': crit}\n",
    "                print(\"Current parameter combination:\")\n",
    "                for parameter, value in params.items():\n",
    "                    print(f\"\\t{parameter}: {value}\")\n",
    "                print()\n",
    "\n",
    "                rf_model = RandomForestClassifier(n_estimators=n_est, criterion=crit, max_depth=m_depth, min_samples_leaf=m_samples_leaf)\n",
    "                score = k_fold_cv(model=rf_model, df=df, metric_funcs=[roc_auc_score])\n",
    "                avg_auc, std = weighted_avg_and_std(np.array(score[\"roc_auc_score\"]))\n",
    "                if avg_auc > best_auc:\n",
    "                    best_auc = avg_auc\n",
    "                    best = params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running, we got the following values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results of the grid search parameter hypertunning:\")\n",
    "for parameter, value in best.items():\n",
    "    print(f\"\\t{parameter}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
