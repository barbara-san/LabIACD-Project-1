{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "One of the models we chose to implement for the purpose of lung cancer classification was a multilayer perceptron, a type of feedfoward neural network.  \n",
    "MLPs are suitable for classification prediction problems and data provided in a tabular format, such as the features CSV file we are working with.\n",
    "\n",
    "We start by importing relevant libraries and dropping useless columns from our CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfold_and_metrics import *\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"final.csv\")\n",
    "df = df.drop(columns=['id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Hypertuning\n",
    "\n",
    "In the machine learning world, it is mostly agreed that a single hidden layer is enough to develop a good neural network model.  \n",
    "\n",
    "Taking this into consideration, we still needed to decide on the number of nodes it should hold, while trying to prevent both under and overfitting. For this, we tested values until 2/3 of the number of input nodes, one of the several rules of thumb for choosing the number of nodes in a hidden layer.  \n",
    "\n",
    "Additionally, we tested different learning rates for our Stochastic gradient descent optimizer and different activation functions for the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_auc = 0\n",
    "best = {}\n",
    "\n",
    "# input_nodes = len(df.columns)-2\n",
    "input_nodes = 50\n",
    "max_n_nodes = input_nodes * 2//3\n",
    "\n",
    "for hidden_layer_act in [\"softmax\", \"relu\", \"sigmoid\"]:\n",
    "    for n_nodes in range(5, max_n_nodes, 10):\n",
    "        for l_rate in [0.001, 0.003, 0.005, 0.007, 0.01]:\n",
    "            params = {'hidden_layer_nodes': n_nodes, 'hidden_layer_activation': hidden_layer_act, 'learning_rate': l_rate}\n",
    "            print(\"Current parameter combination:\")\n",
    "            for parameter, value in params.items():\n",
    "                print(f\"\\t{parameter}: {value}\")\n",
    "            print()\n",
    "\n",
    "            nn_model = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Input((input_nodes,), name=\"input\"),\n",
    "                tf.keras.layers.Dense(n_nodes,activation=hidden_layer_act),\n",
    "                tf.keras.layers.Dense(2,activation='softmax')\n",
    "            ])\n",
    "            nn_model.compile(\n",
    "                optimizer=tf.keras.optimizers.SGD(l_rate), \n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "            )\n",
    "\n",
    "            score = k_fold_cv_keras(compiled_model=nn_model, df=df, pca_components=50)\n",
    "            results = mean_std_results_k_fold_CV(score)\n",
    "\n",
    "            auc_avg = results.iloc[2,1]\n",
    "            if auc_avg > best_auc:\n",
    "                best_auc = auc_avg\n",
    "                best = params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running, we got the following values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results of the grid search parameter hypertunning:\")\n",
    "for parameter, value in best.items():\n",
    "    print(f\"\\t{parameter}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of hidden layers and rule of thumb considered can be read about in the following resources:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
